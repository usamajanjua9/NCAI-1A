{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \ud83e\udded **1. Introduction**\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udc4b **1.1 About Me:**\n",
        "\n",
        "### \ud83c\udf99\ufe0f Speaker Introduction\n",
        "\n",
        "Welcome!  \n",
        "\n",
        "\n",
        "**\ud83d\udc68\u200d\ud83c\udfeb Usama Arshad**\n",
        "- Assistant Professor (Business Analytics), FAST National University, Islamabad  \n",
        "- PhD in Computer Science \u2013 Blockchain & AI, Ghulam Ishaq Khan Institute  \n",
        "- Research Assistant \u2013 National Yunlin University, Taiwan (AI in Healthcare)  \n",
        "- President \u2013 Graduate Students Society, GIKI  \n",
        "- Published Author \u2013 IEEE, Springer, Elsevier (Blockchain, AI, Cybersecurity)  \n",
        "- GitHub: [github.com/usamajanjua9](https://github.com/usamajanjua9)  \n",
        "- LinkedIn: [linkedin.com/in/usamajanjua9](https://linkedin.com/in/usamajanjua9)  \n",
        "- Website: [usamajanjua.com](https://usamajanjua.com)\n",
        "\n",
        "<img src=\"https://isb.nu.edu.pk/Images/Profile/FSM/7078.jpg\" width=\"350\" >\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LnMAAm8CBu3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Module 5: AI for Predictive Maintenance & Asset Management**\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Introduction to Predictive Maintenance**\n",
        "\n",
        "Predictive Maintenance (PdM) is a technique where we **use data, sensors, and AI models to predict equipment failure *before* it happens**.\n",
        "Instead of repairing machines only after they fail, PdM helps companies **take action at the perfect time**\u2014not too early, not too late.\n",
        "\n",
        "It is widely used in industries such as **manufacturing, energy, transportation, aviation, oil & gas, and industrial automation**.\n",
        "\n",
        "---\n",
        "\n",
        "# **1.1 Predictive vs Preventive vs Corrective Maintenance**\n",
        "\n",
        "To understand Predictive Maintenance clearly, we compare it with the other common maintenance strategies.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Corrective Maintenance (Fix after failure)**\n",
        "\n",
        "**Idea:** Wait until the machine breaks, then repair it.\n",
        "\n",
        "**Example:**\n",
        "A motor stops working \u2192 you call a technician \u2192 machine stays offline.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* No planning needed\n",
        "* Low upfront cost\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Unexpected failures\n",
        "* High downtime\n",
        "* Loss of productivity\n",
        "* Emergency repair cost is high\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Preventive Maintenance (Scheduled maintenance)**\n",
        "\n",
        "**Idea:** Maintain after a fixed time, even if the machine is fine.\n",
        "\n",
        "**Example:**\n",
        "Changing car engine oil every 5,000 km, even if it is still usable.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Reduces random failures\n",
        "* Simple and predictable\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* May replace healthy parts\n",
        "* Wastes time and money\n",
        "* Not suitable for complex machines\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Predictive Maintenance (AI + Sensors + Prediction)**\n",
        "\n",
        "**Idea:** Use sensor data to **predict** when a failure will happen, then perform maintenance only when needed.\n",
        "\n",
        "**Example:**\n",
        "If vibration increases beyond normal range, AI predicts that the bearing will fail in 20 days \u2192 maintenance team changes it before failure.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Reduces downtime\n",
        "* Saves cost\n",
        "* Extends asset life\n",
        "* More accurate and data-driven\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Requires sensors\n",
        "* Requires data and models\n",
        "* Needs skilled people initially\n",
        "\n",
        "---\n",
        "\n",
        "### **Easy Summary Chart**\n",
        "\n",
        "| Strategy        | When Maintenance Happens         | Example             | Cost   | Downtime |\n",
        "| --------------- | -------------------------------- | ------------------- | ------ | -------- |\n",
        "| Corrective      | After failure                    | Machine breaks      | High   | High     |\n",
        "| Preventive      | On a fixed schedule              | Every 3 months      | Medium | Medium   |\n",
        "| Predictive (AI) | Based on real machine conditions | AI predicts failure | Low    | Very Low |\n",
        "\n",
        "---\n",
        "\n",
        "# **1.2 Industrial Use Cases of Predictive Maintenance**\n",
        "\n",
        "PdM is used in almost every industry where machines exist.\n",
        "Some real examples:\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Manufacturing Machines**\n",
        "\n",
        "* Predicting **bearing failures** in rotating machines\n",
        "* Monitoring **motor vibration and temperature**\n",
        "* Preventing **conveyor belt breakdowns**\n",
        "* Detecting **tool wear** in CNC machines\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Aviation**\n",
        "\n",
        "* Monitoring turbofan engines\n",
        "* Predicting remaining useful life (RUL) of engine parts\n",
        "* Detecting unusual pressure or temperature behavior\n",
        "\n",
        "NASA\u2019s CMAPSS dataset is a famous example used for PdM research.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Energy Sector**\n",
        "\n",
        "* Wind turbine fault detection\n",
        "* Solar farm inverter failure prediction\n",
        "* Transformer oil temperature rise\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Transportation**\n",
        "\n",
        "* Predicting brake failure in buses\n",
        "* Railway axle and wheel monitoring\n",
        "* Fleet health monitoring\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Oil & Gas**\n",
        "\n",
        "* Pipeline leak prediction using pressure sensors\n",
        "* Valve and pump anomaly detection\n",
        "* Gas compressor failure forecasting\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Smart Buildings**\n",
        "\n",
        "* Air conditioning (HVAC) equipment failure\n",
        "* Generator and UPS health monitoring\n",
        "\n",
        "---\n",
        "\n",
        "### **Simple Conclusion:**\n",
        "\n",
        "If something has **sensors + data + machine parts**, Predictive Maintenance can be applied.\n",
        "\n",
        "---\n",
        "\n",
        "# **1.3 Asset Failure Modes**\n",
        "\n",
        "Failure Mode means **how a machine can fail**.\n",
        "Understanding this helps in selecting the right sensors and AI models.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Mechanical Failures**\n",
        "\n",
        "* Bearing wear\n",
        "* Gearbox damage\n",
        "* Shaft misalignment\n",
        "* Belt cracks\n",
        "* Loose fittings\n",
        "\n",
        "**Sensor Type:** Vibration, speed\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Thermal Failures**\n",
        "\n",
        "* Overheating\n",
        "* Lubrication breakdown\n",
        "* Electrical overload\n",
        "\n",
        "**Sensor Type:** Temperature, current\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Electrical Failures**\n",
        "\n",
        "* Short circuits\n",
        "* Voltage imbalance\n",
        "* Insulation breakdown\n",
        "\n",
        "**Sensor Type:** Voltage, current, thermal cameras\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Environmental Failures**\n",
        "\n",
        "* Moisture\n",
        "* Corrosion\n",
        "* Dust accumulation\n",
        "\n",
        "**Sensor Type:** Humidity, air-quality sensors\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Human/Operational Failures**\n",
        "\n",
        "* Improper handling\n",
        "* Overloading\n",
        "* Poor maintenance schedule\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "\n",
        "Different failure modes \u2192 different sensors \u2192 different AI models.\n",
        "\n",
        "---\n",
        "\n",
        "# **1.4 Predictive Maintenance Workflow**\n",
        "\n",
        "A simple step-by-step process showing how PdM works:\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 1: Data Collection**\n",
        "\n",
        "* Sensors collect vibration, temperature, pressure, etc.\n",
        "* Machines send readings continuously\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 2: Data Storage**\n",
        "\n",
        "* Data sent to cloud or local servers\n",
        "* Stored in time-series format\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 3: Feature Engineering**\n",
        "\n",
        "* Extract meaningful values like:\n",
        "\n",
        "  * Mean\n",
        "  * Standard deviation\n",
        "  * FFT frequencies\n",
        "  * Health index\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 4: Model Training**\n",
        "\n",
        "* Use ML models to detect patterns\n",
        "* Choose model type:\n",
        "\n",
        "  * Random Forest\n",
        "  * XGBoost\n",
        "  * LSTM\n",
        "  * Autoencoders\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 5: Prediction**\n",
        "\n",
        "* Model predicts:\n",
        "\n",
        "  * Upcoming failures\n",
        "  * Remaining Useful Life (RUL)\n",
        "  * Anomalies\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 6: Maintenance Decision**\n",
        "\n",
        "* Maintenance team receives alerts\n",
        "* Replace the part before failure\n",
        "* Reduce downtime\n",
        "\n",
        "---\n",
        "\n",
        "## **Step 7: Continuous Improvement**\n",
        "\n",
        "* Update model with new data\n",
        "* Make predictions more accurate\n",
        "\n",
        "---\n",
        "\n",
        "### **Very Simple Diagram (Text-Based)**\n",
        "\n",
        "```\n",
        "Sensors \u2192 Data Storage \u2192 Feature Engineering \u2192 AI/ML Model \u2192\n",
        "Prediction \u2192 Maintenance Action \u2192 Feedback \u2192 Retrain Model\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **1.5 Benefits and Challenges of Predictive Maintenance**\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Benefits**\n",
        "\n",
        "* **Reduced downtime**\n",
        "* **Lower maintenance cost**\n",
        "* **Longer asset life**\n",
        "* **Higher safety**\n",
        "* **Better production efficiency**\n",
        "* **Maintenance only when needed**\n",
        "* **Data-driven decisions**\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Challenges**\n",
        "\n",
        "* Requires initial investment\n",
        "* Need skilled data engineers / AI engineers\n",
        "* Sensor installation cost\n",
        "* Data cleaning is difficult (missing/noisy data)\n",
        "* Requires proper IT infrastructure\n",
        "* Needs continuous monitoring\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Summary**\n",
        "\n",
        "Predictive Maintenance is one of the most practical applications of AI in industry.\n",
        "It saves cost, avoids failures, improves safety, and helps companies keep machines running without disruption.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "S8oAMl1dBle9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **2. Types of Data in Predictive Maintenance (PdM)**\n",
        "\n",
        "Predictive Maintenance depends completely on **data**.\n",
        "Machines produce different types of data through sensors, operations, and logs.\n",
        "AI models learn patterns from this data to predict failures.\n",
        "\n",
        "The better the data, the more accurate the predictions.\n",
        "\n",
        "We divide PdM data into **five major categories**:\n",
        "\n",
        "1. **Sensor Data**\n",
        "2. **Operational Data**\n",
        "3. **Environmental Data**\n",
        "4. **Failure Logs**\n",
        "5. **Maintenance Records**\n",
        "\n",
        "Each type has its own importance.\n",
        "\n",
        "---\n",
        "\n",
        "# **2.1 Sensor Data**\n",
        "\n",
        "Sensor data is the **heart** of predictive maintenance.\n",
        "Sensors continuously measure the health of machine components.\n",
        "\n",
        "Sensor readings help identify:\n",
        "\n",
        "* Unusual vibration\n",
        "* Sudden temperature increases\n",
        "* Pressure drop\n",
        "* Electrical current spikes\n",
        "* Strange noise patterns\n",
        "\n",
        "Below are the common sensor types and what they measure.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Vibration Data**\n",
        "\n",
        "Vibration sensors (accelerometers) measure how much a machine **shakes**.\n",
        "\n",
        "Why important:\n",
        "\n",
        "* Almost all rotating machines (motors, bearings, compressors, turbines) show early failure signs through vibration.\n",
        "* Misalignment, imbalance, looseness, and bearing wear are all detected from vibration changes.\n",
        "\n",
        "Example data:\n",
        "\n",
        "* Acceleration in X, Y, Z\n",
        "* Frequency peaks (FFT)\n",
        "\n",
        "Real-world use:\n",
        "\n",
        "* Predicting bearing failure 30+ days earlier\n",
        "* Detecting gearbox damage\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Temperature Data**\n",
        "\n",
        "Temperature sensors measure **heat** generated during operation.\n",
        "\n",
        "Why important:\n",
        "\n",
        "* Overheating is the first sign of many failures\n",
        "* Lack of lubrication\n",
        "* Increased friction\n",
        "* Electrical overload\n",
        "* Blocked ventilation\n",
        "\n",
        "Example:\n",
        "\n",
        "* Motor temperature rising from 65\u00b0C \u2192 95\u00b0C indicates imminent failure.\n",
        "\n",
        "Real-world use:\n",
        "\n",
        "* Transformers\n",
        "* Motors\n",
        "* Compressors\n",
        "* Engines\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Pressure Data**\n",
        "\n",
        "Used mainly in:\n",
        "\n",
        "* Hydraulic systems\n",
        "* Oil & gas pipelines\n",
        "* Compressors\n",
        "* Pumps\n",
        "\n",
        "Why important:\n",
        "\n",
        "* A sudden pressure drop \u2192 leakage\n",
        "* High pressure \u2192 clogging or blockage\n",
        "* Pressure fluctuation \u2192 worn-out pumps or valves\n",
        "\n",
        "Example:\n",
        "A gas pipeline pressure dropping by 25% indicates leakage.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Acoustic (Sound) Data**\n",
        "\n",
        "Acoustic sensors capture **sound waves** and noise patterns.\n",
        "\n",
        "Why important:\n",
        "Machines make different sounds when:\n",
        "\n",
        "* Bearings wear\n",
        "* Valves leak\n",
        "* Fans hit obstacles\n",
        "* Motors are overloaded\n",
        "\n",
        "Acoustic AI + spectrograms = Detect hidden machine problems.\n",
        "\n",
        "Used in:\n",
        "\n",
        "* HVAC systems\n",
        "* Engines\n",
        "* Fans\n",
        "* Industrial pumps\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Voltage/Current Data**\n",
        "\n",
        "Electrical sensors measure:\n",
        "\n",
        "* Voltage\n",
        "* Current\n",
        "* Power factor\n",
        "* Load imbalance\n",
        "* Current spikes (inrush currents)\n",
        "\n",
        "Why important:\n",
        "\n",
        "* Electrical faults occur before mechanical failures\n",
        "* Insulation damage\n",
        "* Motor winding short circuits\n",
        "* Overloading\n",
        "\n",
        "Example:\n",
        "A motor drawing 30% extra current \u2192 upcoming failure.\n",
        "\n",
        "Used in:\n",
        "\n",
        "* Industrial motors\n",
        "* Electric vehicles\n",
        "* Transformers\n",
        "* UPS/Generators\n",
        "\n",
        "---\n",
        "\n",
        "# **2.2 Operational Data**\n",
        "\n",
        "Operational data describes **how the machine is being used**.\n",
        "\n",
        "It does NOT come from sensors, but from the machine\u2019s internal control systems (PLC, SCADA, IoT platform).\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Load**\n",
        "\n",
        "Indicates how much work the machine is doing.\n",
        "\n",
        "Example:\n",
        "\n",
        "* A motor running at 95% load is more likely to fail than one running at 60%.\n",
        "\n",
        "If load stays high for long periods \u2192 stress \u2192 early failure.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Speed / RPM**\n",
        "\n",
        "Shows how fast rotating equipment is running.\n",
        "\n",
        "Important for:\n",
        "\n",
        "* Fans\n",
        "* Turbines\n",
        "* Compressors\n",
        "* Engines\n",
        "\n",
        "Example:\n",
        "High RPM with high vibration = critical warning.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Runtime**\n",
        "\n",
        "Total time the machine has been running.\n",
        "\n",
        "Used to compute:\n",
        "\n",
        "* Wear rate\n",
        "* Remaining usable time\n",
        "* Maintenance scheduling\n",
        "\n",
        "Example:\n",
        "A pump running for 10,000 hours without service needs urgent inspection.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Duty Cycles**\n",
        "\n",
        "Duty cycle = % of time a machine is ON vs OFF.\n",
        "\n",
        "Example:\n",
        "\n",
        "* 80% duty cycle \u2192 machine is ON most of the time\n",
        "* 20% duty cycle \u2192 machine rests often\n",
        "\n",
        "Machines with high duty cycles fail sooner.\n",
        "\n",
        "---\n",
        "\n",
        "# **2.3 Environmental Data**\n",
        "\n",
        "Environment strongly affects machine lifespan.\n",
        "\n",
        "Common environmental readings:\n",
        "\n",
        "* Temperature\n",
        "* Humidity\n",
        "* Dust levels\n",
        "* Air quality\n",
        "* Vibrations from surroundings\n",
        "* Water leakage\n",
        "\n",
        "Examples:\n",
        "\n",
        "* High humidity causes corrosion\n",
        "* Dust blocks filters and fans\n",
        "* Very cold temperature slows lubrication flow\n",
        "\n",
        "Real-world scenario:\n",
        "A factory near a steel plant experiences heavy dust \u2192 faster cooling system failure.\n",
        "\n",
        "---\n",
        "\n",
        "# **2.4 Failure Logs**\n",
        "\n",
        "Failure logs store **all past failures** of machines.\n",
        "\n",
        "They include:\n",
        "\n",
        "* Date of failure\n",
        "* Type of failure\n",
        "* Symptoms observed\n",
        "* Sensor values before failure\n",
        "* Root cause (if known)\n",
        "* Replaced parts\n",
        "\n",
        "Why important:\n",
        "AI models use this for supervised learning.\n",
        "They learn patterns that *lead to* failure.\n",
        "\n",
        "Example:\n",
        "If every bearing failure was preceded by vibration above 5g RMS \u2192 model learns this pattern.\n",
        "\n",
        "---\n",
        "\n",
        "# **2.5 Maintenance Records**\n",
        "\n",
        "Maintenance records show **what maintenance actions were performed**.\n",
        "\n",
        "They include:\n",
        "\n",
        "* What part was replaced\n",
        "* When service happened\n",
        "* Work done\n",
        "* Technician notes\n",
        "* Cost\n",
        "* Preventive vs corrective\n",
        "* Tools used\n",
        "\n",
        "Why important:\n",
        "\n",
        "* Helps AI understand which actions solved which problems\n",
        "* Helps calculate maintenance cost savings\n",
        "* Helps optimize schedules\n",
        "\n",
        "Example:\n",
        "If lubrication was done every 500 hours and failures disappeared \u2192 model learns optimal intervals.\n",
        "\n",
        "---\n",
        "\n",
        "# **Summary: Why All These Data Types Matter**\n",
        "\n",
        "| Data Type           | Purpose                            |\n",
        "| ------------------- | ---------------------------------- |\n",
        "| Sensor Data         | Detect early signs of failure      |\n",
        "| Operational Data    | Understand machine stress          |\n",
        "| Environmental Data  | Detect external effects            |\n",
        "| Failure Logs        | Train models to recognize failures |\n",
        "| Maintenance Records | Improve scheduling and reliability |\n",
        "\n",
        "Together, they create a **complete picture** of machine health.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UC4WJ9g8EHcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **3. Feature Engineering in Predictive Maintenance**\n",
        "\n",
        "Feature Engineering means **converting raw sensor data into meaningful information** that AI models can understand.\n",
        "\n",
        "In Predictive Maintenance (PdM), sensor data comes in the form of **time-series signals** (continuous readings over time).\n",
        "We extract features from these signals to:\n",
        "\n",
        "* Detect early signs of machine failure\n",
        "* Understand degradation patterns\n",
        "* Predict Remaining Useful Life (RUL)\n",
        "* Improve model accuracy\n",
        "\n",
        "Think of feature engineering as converting messy signals into useful numbers.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.1 Statistical Features**\n",
        "\n",
        "These features capture **basic patterns** in the data.\n",
        "They are calculated over a certain time window (e.g., the last 5 seconds of vibration data).\n",
        "\n",
        "Statistical features are **simple but very powerful** in detecting faults.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Mean**\n",
        "\n",
        "The average value of the signal.\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* High mean temperature \u2192 overheating\n",
        "* Increasing vibration mean \u2192 wear increasing over time\n",
        "\n",
        "Example:\n",
        "If vibration mean increases slowly, it indicates bearing degradation.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Standard Deviation (STD)**\n",
        "\n",
        "Shows **how much the signal varies** around the mean.\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* High STD = unstable machine behavior\n",
        "* Low STD = stable operation\n",
        "\n",
        "In vibration analysis, increasing STD means the machine is shaking irregularly.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 RMS (Root Mean Square)**\n",
        "\n",
        "RMS measures the **energy** of the signal.\n",
        "\n",
        "Why important in PdM:\n",
        "\n",
        "* RMS is the most common feature for vibration data\n",
        "* Higher RMS \u2192 more vibration \u2192 more wear\n",
        "\n",
        "For rotating machines, RMS is used to detect:\n",
        "\n",
        "* imbalance\n",
        "* misalignment\n",
        "* bearing wear\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Skewness**\n",
        "\n",
        "Measures whether the signal is **tilted** more to the left or right.\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* Sudden changes in skewness indicate unusual vibration patterns.\n",
        "\n",
        "If skewness becomes positive or negative suddenly \u2192 new fault developing.\n",
        "\n",
        "---\n",
        "\n",
        "## **\u2714 Kurtosis**\n",
        "\n",
        "Measures how **sharp or flat** the signal peaks are.\n",
        "\n",
        "Why important:\n",
        "\n",
        "* High kurtosis \u2192 sharp spikes \u2192 early bearing faults\n",
        "* Low kurtosis \u2192 smooth signal \u2192 normal operation\n",
        "\n",
        "Kurtosis is one of the earliest indicators of bearing damage.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.2 Time-Domain Features**\n",
        "\n",
        "Time-domain features are extracted from the **actual sensor readings over time**.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* Peak value\n",
        "* Crest factor\n",
        "* Rise time\n",
        "* Zero-crossing rate\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* They directly capture machine behavior\n",
        "* Useful for mechanical, electrical, and thermal faults\n",
        "* Good for anomaly detection\n",
        "\n",
        "Simple example:\n",
        "If vibration peak suddenly increases, something is hitting inside the machine.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.3 Frequency-Domain Features (FFT)**\n",
        "\n",
        "Machines produce faults at **specific frequencies**.\n",
        "By using **Fast Fourier Transform (FFT)**, we convert the signal from time \u2192 frequency domain.\n",
        "\n",
        "Why FFT is useful:\n",
        "\n",
        "* Early bearing faults create vibration at specific frequencies\n",
        "* Gear defects show unique frequency patterns\n",
        "* Unbalance/looseness has signature peaks\n",
        "\n",
        "Common FFT features:\n",
        "\n",
        "* Dominant frequency\n",
        "* Harmonic peaks\n",
        "* Spectral energy\n",
        "* Spectral entropy\n",
        "\n",
        "Example:\n",
        "A bearing creates a \u201cfault frequency\u201d when damaged. FFT helps detect it.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.4 Rolling Window Features**\n",
        "\n",
        "Rolling windows calculate features over a **moving window** of time.\n",
        "\n",
        "Example:\n",
        "Take vibration data \u2192\n",
        "Calculate mean every 5 seconds \u2192\n",
        "Slide the window forward \u2192\n",
        "Repeat.\n",
        "\n",
        "Helpful for:\n",
        "\n",
        "* Tracking gradual degradation\n",
        "* Smoothing noisy data\n",
        "* Predicting RUL\n",
        "\n",
        "Rolling features used:\n",
        "\n",
        "* Rolling mean\n",
        "* Rolling STD\n",
        "* Rolling RMS\n",
        "* Rolling FFT energy\n",
        "\n",
        "Example:\n",
        "If rolling RMS continues increasing \u2192 machine is approaching failure.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.5 Lagged Features**\n",
        "\n",
        "Lag features are **previous values** included as new features.\n",
        "\n",
        "Example:\n",
        "\n",
        "* Vibration at time t-1\n",
        "* Temperature at time t-5\n",
        "* Pressure at time t-10\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* Helps models understand trends\n",
        "* Captures degradation patterns\n",
        "* Makes time-series models perform better\n",
        "\n",
        "Example:\n",
        "If previous 10 readings show rising temperature \u2192 overheating is near.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.6 Sensor Fusion Features**\n",
        "\n",
        "Sensor fusion means **combining multiple sensors** to create new features.\n",
        "\n",
        "Why important:\n",
        "\n",
        "* Machines have multiple types of sensors (vibration + temperature + current)\n",
        "* Combining them gives a clearer health picture\n",
        "\n",
        "Examples:\n",
        "\n",
        "* \"Thermal Stress Index\" = temperature + load\n",
        "* \"Mechanical Stress Index\" = vibration + speed\n",
        "* \"Energy Consumption Index\" = current + runtime\n",
        "\n",
        "Real world:\n",
        "A motor may heat only when load is high + vibration is increasing \u2192 strong failure sign.\n",
        "\n",
        "---\n",
        "\n",
        "# **3.7 Health Index (HI)**\n",
        "\n",
        "Health Index is a single number that represents **overall machine health**.\n",
        "\n",
        "Ranges:\n",
        "\n",
        "* 1 \u2192 Healthy\n",
        "* 0 \u2192 Failed\n",
        "\n",
        "Or\n",
        "\n",
        "* 100 \u2192 Excellent\n",
        "* 0 \u2192 Broken\n",
        "\n",
        "How it's created:\n",
        "\n",
        "* Combine multiple features\n",
        "* Normalize values\n",
        "* Use ML to compute a health score\n",
        "\n",
        "Why useful:\n",
        "\n",
        "* Easy to visualize degradation\n",
        "* Good for dashboards\n",
        "* Helps maintenance teams understand machine condition quickly\n",
        "\n",
        "---\n",
        "\n",
        "# **3.8 Remaining Useful Life (RUL) Labels**\n",
        "\n",
        "RUL = **how long before the machine fails**.\n",
        "\n",
        "It is the most important label in Predictive Maintenance.\n",
        "\n",
        "Example:\n",
        "\n",
        "* RUL = 50 hours \u2192 still fine\n",
        "* RUL = 5 hours \u2192 urgent maintenance\n",
        "* RUL = 0 \u2192 failure\n",
        "\n",
        "How RUL labels are created:\n",
        "\n",
        "1. Find the failure point in training data\n",
        "2. Count backwards from failure\n",
        "3. Assign RUL values for each point\n",
        "\n",
        "Example:\n",
        "\n",
        "| Time | Condition   | RUL |\n",
        "| ---- | ----------- | --- |\n",
        "| t1   | good        | 50  |\n",
        "| t2   | slight wear | 40  |\n",
        "| t3   | heavy wear  | 10  |\n",
        "| t4   | critical    | 1   |\n",
        "| t5   | failure     | 0   |\n",
        "\n",
        "RUL helps AI models predict:\n",
        "\n",
        "* When to schedule maintenance\n",
        "* When to replace parts\n",
        "* How to avoid downtime\n",
        "\n",
        "---\n",
        "\n",
        "# **Summary**\n",
        "\n",
        "Feature Engineering converts raw sensor data into meaningful information.\n",
        "\n",
        "| Feature Type             | Purpose                             |\n",
        "| ------------------------ | ----------------------------------- |\n",
        "| Statistical Features     | Capture basic patterns              |\n",
        "| Time-Domain Features     | Detect faults directly from signals |\n",
        "| Frequency Features (FFT) | Find fault frequencies              |\n",
        "| Rolling Windows          | Track slow degradation              |\n",
        "| Lagged Features          | Capture historical behavior         |\n",
        "| Sensor Fusion            | Combine multi-sensor data           |\n",
        "| Health Index             | Summarize machine condition         |\n",
        "| RUL Labels               | Predict failure time                |\n",
        "\n",
        "Together, these features help AI models understand machine behavior and make accurate predictions.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jAE_3eSfEtEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **4. Models for Predictive Maintenance**\n",
        "\n",
        "Predictive Maintenance uses AI/ML models to understand patterns in machine behavior and forecast failures.\n",
        "Below, each model includes a **clear, technical explanation** of *what it is* and *why it is used*\u2014but still in simple language.\n",
        "\n",
        "---\n",
        "\n",
        "# **4.1 Logistic Regression**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Logistic Regression is a **probabilistic classification model** that uses a mathematical function called the **sigmoid** to convert input features into a probability between 0 and 1.\n",
        "It is not \u201cregression\u201d in the normal sense\u2014it's actually a **binary classifier**.\n",
        "\n",
        "It tries to find a straight-line boundary (hyperplane) that separates two classes:\n",
        "\n",
        "* Healthy (0)\n",
        "* Faulty (1)\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Good for simple yes/no predictions\n",
        "* Works well when data is linearly separable\n",
        "* Fast and interpretable\n",
        "\n",
        "---\n",
        "\n",
        "# **4.2 Decision Trees**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "A Decision Tree is a **flowchart-like model** that splits data based on the most important features.\n",
        "At each step (node), it asks a question like:\n",
        "\n",
        "> \u201cIs vibration RMS > 5?\u201d\n",
        "> Yes \u2192 go to left\n",
        "> No \u2192 go to right\n",
        "\n",
        "It learns these rules automatically from data.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Very easy to interpret\n",
        "* Captures nonlinear patterns\n",
        "* Useful for root-cause explanations\n",
        "\n",
        "---\n",
        "\n",
        "# **4.3 Random Forest**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Random Forest is an **ensemble model** made of many Decision Trees.\n",
        "Each tree sees different parts of the data (bagging), and all trees vote on the final output.\n",
        "\n",
        "This reduces overfitting and increases accuracy.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Handles noisy sensor data\n",
        "* Captures complex relationships\n",
        "* Works well even with many features (vibration, temperature, RPM, etc.)\n",
        "\n",
        "---\n",
        "\n",
        "# **4.4 XGBoost**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "XGBoost is a **gradient boosting algorithm** that builds trees sequentially.\n",
        "Each new tree focuses on correcting errors made by previous trees.\n",
        "It uses advanced techniques like:\n",
        "\n",
        "* shrinkage (learning rate)\n",
        "* regularization (to prevent overfitting)\n",
        "* parallel processing\n",
        "\n",
        "This makes it one of the most powerful ML models.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* High accuracy on tabular (feature-based) data\n",
        "* Handles missing data naturally\n",
        "* Excellent for RUL and fault classification\n",
        "\n",
        "---\n",
        "\n",
        "# **4.5 SVM (Support Vector Machine)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "SVM finds the **best boundary (hyperplane)** that maximizes the margin between classes.\n",
        "It uses **kernels** to handle non-linear patterns:\n",
        "\n",
        "* linear\n",
        "* radial (RBF)\n",
        "* polynomial\n",
        "\n",
        "SVM tries to maximize the distance between the hyperplane and the nearest points (support vectors).\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Excellent for detecting subtle differences\n",
        "* Good for high-dimensional data\n",
        "* Effective when dataset is small but informative\n",
        "\n",
        "---\n",
        "\n",
        "# **4.6 KNN (K-Nearest Neighbors)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "KNN is a **distance-based model**.\n",
        "When a new data point comes in, it looks at the \u201cK\u201d most similar past examples and predicts based on them.\n",
        "\n",
        "No training happens\u2014only comparison at prediction time.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Works well when failure patterns repeat\n",
        "* Easy to implement\n",
        "* Good for early prototyping\n",
        "\n",
        "---\n",
        "\n",
        "# **4.7 1D CNN (1D Convolutional Neural Network)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "A 1D CNN applies **filters (kernels)** over time-series data to automatically learn important patterns.\n",
        "It captures:\n",
        "\n",
        "* peaks\n",
        "* periodic vibrations\n",
        "* sudden anomalies\n",
        "* frequency-like features\n",
        "\n",
        "CNNs extract these patterns without manual feature engineering.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Ideal for raw vibration/pressure signals\n",
        "* Learns local time patterns very well\n",
        "* Great for fault-type classification\n",
        "\n",
        "---\n",
        "\n",
        "# **4.8 LSTM (Long Short-Term Memory Network)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "LSTM is a **recurrent neural network (RNN)** designed to remember information over long periods using special components:\n",
        "\n",
        "* **input gate**\n",
        "* **forget gate**\n",
        "* **output gate**\n",
        "\n",
        "These gates control what the network remembers and forgets.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Captures long-term degradation\n",
        "* Excellent for continuous sensor streams\n",
        "* Best for Remaining Useful Life (RUL) prediction\n",
        "\n",
        "---\n",
        "\n",
        "# **4.9 GRU (Gated Recurrent Unit)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "GRU is a simplified version of LSTM with only two gates:\n",
        "\n",
        "* reset gate\n",
        "* update gate\n",
        "\n",
        "It retains the ability to learn long-term patterns but is computationally lighter.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Faster than LSTM\n",
        "* Great for real-time or edge computing\n",
        "* Similar performance with fewer parameters\n",
        "\n",
        "---\n",
        "\n",
        "# **4.10 Autoencoders**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "An Autoencoder is a **neural network that tries to compress input data and then reconstruct it**.\n",
        "It has:\n",
        "\n",
        "* **Encoder** \u2192 compresses data\n",
        "* **Decoder** \u2192 reconstructs data\n",
        "\n",
        "If reconstruction error is high \u2192 anomaly detected.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Works even when failure data is rare\n",
        "* Learns normal behavior extremely well\n",
        "* Good for early anomaly detection\n",
        "\n",
        "---\n",
        "\n",
        "# **4.11 CNN + LSTM Hybrid**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "A hybrid architecture that combines:\n",
        "\n",
        "* **CNN layers** \u2192 extract local features from raw signals\n",
        "* **LSTM layers** \u2192 understand long-term temporal behavior\n",
        "\n",
        "This model captures both **short-term patterns** and **long-term degradation**.\n",
        "\n",
        "### **Why it works for PdM:**\n",
        "\n",
        "* Best for complex industrial datasets\n",
        "* Used in NASA CMAPSS engine dataset\n",
        "* High accuracy in RUL prediction\n",
        "\n",
        "---\n",
        "\n",
        "# **Final Summary**\n",
        "\n",
        "| Model               | Technical Description                 | Best Use Case in PdM      |\n",
        "| ------------------- | ------------------------------------- | ------------------------- |\n",
        "| Logistic Regression | Probabilistic linear classifier       | Healthy vs Faulty         |\n",
        "| Decision Tree       | Rule-based recursive splitting        | Simple diagnostics        |\n",
        "| Random Forest       | Ensemble of many trees                | Fault classification      |\n",
        "| XGBoost             | Gradient-boosted trees                | High-accuracy predictions |\n",
        "| SVM                 | Maximized-margin classifier           | Subtle fault separation   |\n",
        "| KNN                 | Distance-based classifier             | Pattern matching          |\n",
        "| 1D CNN              | Convolution filters for raw signals   | Vibration/Acoustic faults |\n",
        "| LSTM                | Sequence-learning RNN                 | RUL prediction            |\n",
        "| GRU                 | Light-weight LSTM                     | Real-time PdM             |\n",
        "| Autoencoder         | Reconstruction-based anomaly detector | Rare failure detection    |\n",
        "| CNN + LSTM          | Hybrid temporal-spatial model         | Complex RUL models        |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RJ0uubCTHbn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **5. Core Predictive Maintenance Tasks**\n",
        "\n",
        "Predictive Maintenance (PdM) is not just one task.\n",
        "It involves several AI-driven tasks that work together to monitor machine health, detect problems, and forecast failures.\n",
        "\n",
        "Each task has a unique purpose, different data needs, and specific ML models suited for it.\n",
        "\n",
        "We explain all **six key tasks** below.\n",
        "\n",
        "---\n",
        "\n",
        "# **5.1 Fault Detection**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Fault detection answers the question:\n",
        "\n",
        "> **\u201cIs something wrong with the machine right now?\u201d**\n",
        "\n",
        "It is the simplest PdM task:\n",
        "\n",
        "* No need to identify *what* the fault is\n",
        "* Only detect if the current state is normal or abnormal\n",
        "\n",
        "### **How it works technically:**\n",
        "\n",
        "* Model learns patterns of healthy machine behavior\n",
        "* Compares current sensor readings (vibration, temperature, current)\n",
        "* If values deviate beyond learned boundaries \u2192 \u201cFault Detected\u201d\n",
        "\n",
        "### **Common models used:**\n",
        "\n",
        "* Logistic Regression\n",
        "* Decision Trees\n",
        "* Random Forest\n",
        "* SVM\n",
        "* Autoencoders (for unlabeled data)\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "If vibration RMS exceeds the normal pattern the model learned, it raises a fault alert.\n",
        "\n",
        "---\n",
        "\n",
        "# **5.2 Fault Classification**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Fault classification answers:\n",
        "\n",
        "> **\u201cWhat type of fault is happening?\u201d**\n",
        "\n",
        "Instead of just saying \u201cfault,\u201d the model categorizes the problem.\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "Uses supervised learning where each failure type has a label.\n",
        "\n",
        "Classes can be:\n",
        "\n",
        "* Imbalance\n",
        "* Misalignment\n",
        "* Bearing inner-race fault\n",
        "* Bearing outer-race fault\n",
        "* Gear tooth damage\n",
        "* Electrical winding fault\n",
        "\n",
        "### **How it works:**\n",
        "\n",
        "* Extract features (RMS, kurtosis, FFT peaks)\n",
        "* Train multi-class models\n",
        "* Classify new data into the correct fault category\n",
        "\n",
        "### **Common models used:**\n",
        "\n",
        "* Random Forest\n",
        "* XGBoost\n",
        "* 1D CNN\n",
        "* CNN + LSTM\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Vibration pattern shows a peak at a specific frequency \u2192 classified as \u201cBearing Outer Race Fault\u201d.\n",
        "\n",
        "---\n",
        "\n",
        "# **5.3 Anomaly Detection**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Anomaly detection identifies **unusual patterns** that do NOT match normal behavior.\n",
        "\n",
        "It answers:\n",
        "\n",
        "> **\u201cIs something happening that has never happened before?\u201d**\n",
        "\n",
        "This is useful when:\n",
        "\n",
        "* Failure data is limited\n",
        "* Machine rarely breaks\n",
        "* New kinds of faults appear that were never labeled\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "Models learn only **normal** data.\n",
        "If reconstruction error or deviation is high \u2192 anomaly.\n",
        "\n",
        "### **Common models used:**\n",
        "\n",
        "* Autoencoders\n",
        "* Isolation Forest\n",
        "* One-Class SVM\n",
        "* LSTM Autoencoders\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Machine produces a new vibration pattern not seen in training \u2192 anomaly flagged \u2192 maintenance team investigates.\n",
        "\n",
        "---\n",
        "\n",
        "# **5.4 Remaining Useful Life (RUL) Prediction**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "RUL prediction answers the most important question in PdM:\n",
        "\n",
        "> **\u201cHow much time is left before this machine fails?\u201d**\n",
        "\n",
        "It is a **regression** problem (predict continuous value).\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "* Track sensor values over time\n",
        "* Learn degradation trends\n",
        "* Predict how many hours/cycles remain until failure\n",
        "\n",
        "RUL labels are created by counting backward from the failure point.\n",
        "\n",
        "### **Models used:**\n",
        "\n",
        "* LSTM\n",
        "* GRU\n",
        "* CNN + LSTM\n",
        "* XGBoost\n",
        "* Linear Regression (baseline)\n",
        "\n",
        "### **Why RUL matters:**\n",
        "\n",
        "* Helps schedule maintenance\n",
        "* Avoids unnecessary replacements\n",
        "* Maximizes machine lifespan\n",
        "* Minimizes downtime\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Model predicts:\n",
        "\n",
        "* RUL = 25 hours \u2192 Prepare maintenance\n",
        "* RUL = 5 hours \u2192 Urgent replacement required\n",
        "\n",
        "---\n",
        "\n",
        "# **5.5 Health Scoring**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Health Scoring converts multiple sensor readings into a **single number** that represents machine health.\n",
        "\n",
        "Example scale:\n",
        "\n",
        "* 100 \u2192 Excellent\n",
        "* 70 \u2192 Minor wear\n",
        "* 40 \u2192 Medium degradation\n",
        "* 20 \u2192 High risk\n",
        "* 0 \u2192 Failure\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "Health score is created by:\n",
        "\n",
        "* Normalizing features (vibration, temperature, current)\n",
        "* Weighting their importance\n",
        "* Combining them into one index\n",
        "* Sometimes using ML to compute it\n",
        "\n",
        "### **Benefits:**\n",
        "\n",
        "* Easy for maintenance teams\n",
        "* Good for dashboards\n",
        "* Helps monitor long-term trends\n",
        "\n",
        "### **Models used:**\n",
        "\n",
        "* Random Forest (probability-based)\n",
        "* Autoencoders (reconstruction error as score)\n",
        "* LSTM (trend-based scoring)\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "A motor\u2019s health score drops from 90 \u2192 65 \u2192 40 \u2192 15 over months \u2192 clear degradation.\n",
        "\n",
        "---\n",
        "\n",
        "# **5.6 Degradation Modelling**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Degradation modelling tracks how machine performance declines over time.\n",
        "\n",
        "It answers:\n",
        "\n",
        "> **\u201cHow is the machine wearing out?\u201d**\n",
        "> **\u201cIs it degrading slowly or rapidly?\u201d**\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "Models analyze long-term sensor trends:\n",
        "\n",
        "* increasing vibration\n",
        "* rising temperature\n",
        "* decreasing efficiency\n",
        "* growing noise\n",
        "\n",
        "Degradation models often produce a **curve** representing the machine\u2019s decline.\n",
        "\n",
        "### **Models used:**\n",
        "\n",
        "* LSTM\n",
        "* GRU\n",
        "* Time-series models (ARIMA, Prophet)\n",
        "* Polynomial regression\n",
        "* CNN-LSTM (for complex patterns)\n",
        "\n",
        "### **Why useful:**\n",
        "\n",
        "* Helps detect early warning patterns\n",
        "* Supports planning for future maintenance\n",
        "* Identifies sudden vs gradual degradation\n",
        "* Used heavily in turbine/engine analysis\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "A bearing's vibration RMS increases slowly for 200 hours \u2192 then sharply rises \u2192 indicates approaching failure.\n",
        "\n",
        "---\n",
        "\n",
        "# **Summary Chart**\n",
        "\n",
        "| Task                  | Main Question             | Output            | Typical Models                        |\n",
        "| --------------------- | ------------------------- | ----------------- | ------------------------------------- |\n",
        "| Fault Detection       | Is there a fault?         | Normal/Faulty     | Logistic Regression, SVM, Autoencoder |\n",
        "| Fault Classification  | What fault is it?         | Fault type        | Random Forest, CNN                    |\n",
        "| Anomaly Detection     | Is this behavior unusual? | Anomaly/Normal    | Autoencoder, Isolation Forest         |\n",
        "| RUL Prediction        | When will it fail?        | Hours/cycles left | LSTM, GRU, XGBoost                    |\n",
        "| Health Scoring        | How healthy is it?        | 0\u2013100 score       | RF, Autoencoder                       |\n",
        "| Degradation Modelling | How is health changing?   | Trend curve       | LSTM, GRU                             |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QVfGskABIhD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **6. Evaluation Metrics**\n",
        "\n",
        "To measure how well Predictive Maintenance models work, we use evaluation metrics.\n",
        "These metrics help us evaluate:\n",
        "\n",
        "* Classification performance (fault vs no fault)\n",
        "* Anomaly detection\n",
        "* Regression tasks (RUL prediction)\n",
        "* Overall model reliability\n",
        "\n",
        "Each metric answers a different question about model quality.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.1 Accuracy**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Accuracy measures **how many predictions the model got correct** out of all predictions.\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}}\n",
        "$\n",
        "\n",
        "### **When useful:**\n",
        "\n",
        "* When classes are balanced (equal healthy and faulty samples)\n",
        "\n",
        "### **Limitation:**\n",
        "\n",
        "If 95% of machine data is \u201chealthy,\u201d a model could predict \u201chealthy\u201d always and still get 95% accuracy \u2192 misleading.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Out of 100 predictions, 90 are correct \u2192 Accuracy = 90%\n",
        "\n",
        "---\n",
        "\n",
        "# **6.2 Precision**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Precision tells us:\n",
        "\n",
        "> \u201cOf all the cases where the model predicted **fault**, how many were actually faults?\u201d\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$\n",
        "\n",
        "Where:\n",
        "\n",
        "* **TP** = True Positive\n",
        "* **FP** = False Positive\n",
        "\n",
        "### **Why important in PdM:**\n",
        "\n",
        "A low precision means many **false alarms**, which wastes maintenance time.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Model predicts 20 faults, but only 10 are real \u2192 Precision = 50%.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.3 Recall (Sensitivity)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Recall answers:\n",
        "\n",
        "> \u201cOut of all **actual faults**, how many did the model detect?\u201d\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$\n",
        "\n",
        "Where:\n",
        "\n",
        "* **FN** = False Negative (missed faults)\n",
        "\n",
        "### **Why important in PdM:**\n",
        "\n",
        "Missing a fault (**false negative**) is dangerous because it can cause unplanned machine failure \u2192 costly downtime.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "There were 15 actual faults; model detected only 10 \u2192 Recall = 66%.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.4 F1-Score**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "F1-score combines **Precision and Recall** into one balanced score.\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{F1} = 2 \\cdot \\frac{(\\text{Precision} \\cdot \\text{Recall})}{(\\text{Precision} + \\text{Recall})}\n",
        "$\n",
        "\n",
        "### **Why useful:**\n",
        "\n",
        "* Best metric when classes are imbalanced\n",
        "* Penalizes both false alarms and missed faults\n",
        "* Used widely for fault detection/classification\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "If Precision = 0.8 and Recall = 0.6 \u2192 F1 \u2248 0.69.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.5 AUC-ROC (Area Under ROC Curve)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "AUC-ROC measures how well the model separates **healthy vs faulty** classes across different thresholds.\n",
        "\n",
        "### **ROC Curve axes:**\n",
        "\n",
        "* X-axis: False Positive Rate\n",
        "* Y-axis: True Positive Rate\n",
        "\n",
        "### **AUC Value:**\n",
        "\n",
        "* 1.0 \u2192 Perfect model\n",
        "* 0.5 \u2192 Random guessing\n",
        "* 0.0 \u2192 Completely wrong\n",
        "\n",
        "### **Why important in PdM:**\n",
        "\n",
        "* Helps compare models\n",
        "* Shows how well the model detects faults across all possible settings\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "AUC = 0.92 \u2192 Excellent fault detection capability.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.6 RMSE (Root Mean Square Error)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "RMSE measures how far predictions are from actual values in **regression tasks**, like RUL prediction.\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum (y_{\\text{true}} - y_{\\text{pred}})^2 }\n",
        "$\n",
        "\n",
        "### **Why important:**\n",
        "\n",
        "* Penalizes large errors heavily\n",
        "* Good for RUL tasks where large mistakes cause operational risk\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "If model predicts RUL = 100 hours but true was 50 \u2192 large RMSE penalty.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.7 MAE (Mean Absolute Error)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "MAE measures the **average absolute difference** between predicted and actual values.\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{MAE} = \\frac{1}{N} \\sum |y_{\\text{true}} - y_{\\text{pred}}|\n",
        "$\n",
        "\n",
        "### **Why useful:**\n",
        "\n",
        "* Easy to interpret\n",
        "* Treats all errors equally\n",
        "* Good for general RUL prediction\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "If errors are: 5, 10, 15 \u2192 MAE = 10.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.8 MAPE (Mean Absolute Percentage Error)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "MAPE measures the **percentage error** between predicted and actual values.\n",
        "\n",
        "### **Formula:**\n",
        "\n",
        "$\n",
        "\\text{MAPE} = \\frac{100}{N} \\sum \\left| \\frac{y_{\\text{true}} - y_{\\text{pred}}}{y_{\\text{true}}} \\right|\n",
        "$\n",
        "\n",
        "### **Why useful:**\n",
        "\n",
        "* Good when RUL values vary a lot\n",
        "* Helps understand error in percentage form\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "True RUL = 100, Predicted = 90 \u2192 MAPE = 10%.\n",
        "\n",
        "---\n",
        "\n",
        "# **6.9 RUL-Specific Score Functions**\n",
        "\n",
        "### **What they are:**\n",
        "\n",
        "Some industries define special metrics to evaluate Remaining Useful Life (RUL) prediction accuracy.\n",
        "\n",
        "### **Why needed:**\n",
        "\n",
        "Because:\n",
        "\n",
        "* Overestimating RUL (predicting too high) is dangerous\n",
        "* Underestimating RUL (predicting too low) wastes money\n",
        "\n",
        "So the scoring function often penalizes one more than the other.\n",
        "\n",
        "### **Examples:**\n",
        "\n",
        "#### **1. NASA CMAPSS Scoring Function**\n",
        "\n",
        "Widely used in turbofan RUL tasks:\n",
        "\n",
        "* Small penalty for early replacement\n",
        "* Big penalty for late replacement (predicting too high)\n",
        "\n",
        "#### **2. Weighted Error Metrics**\n",
        "\n",
        "$\n",
        "\\text{Score} = a \\times \\text{Late Error} + b \\times \\text{Early Error}\n",
        "$\n",
        "Where **a > b**.\n",
        "\n",
        "#### **3. Asymmetric Loss Functions**\n",
        "\n",
        "Custom loss functions:\n",
        "\n",
        "* Penalize overestimation more\n",
        "* Encourage safer maintenance schedules\n",
        "\n",
        "### **Real meaning:**\n",
        "\n",
        "RUL models must not say a machine will survive 50 more hours when it will actually fail in 5.\n",
        "\n",
        "---\n",
        "\n",
        "# **Summary Table**\n",
        "\n",
        "| Metric    | Type           | Best For                  | Interpretation                |\n",
        "| --------- | -------------- | ------------------------- | ----------------------------- |\n",
        "| Accuracy  | Classification | Balanced data             | Overall correctness           |\n",
        "| Precision | Classification | Avoid false alarms        | Fault prediction quality      |\n",
        "| Recall    | Classification | Avoid missed faults       | Safety-critical detection     |\n",
        "| F1-score  | Classification | Imbalanced datasets       | Balance of Precision + Recall |\n",
        "| AUC-ROC   | Classification | Model comparison          | Fault separability            |\n",
        "| RMSE      | Regression     | RUL                       | Penalizes large errors        |\n",
        "| MAE       | Regression     | RUL                       | Average error                 |\n",
        "| MAPE      | Regression     | RUL                       | Percentage-based error        |\n",
        "| RUL Score | Regression     | Safety-critical RUL tasks | Penalizes dangerous mistakes  |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L3yW6TNxIwUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **7. Asset Management Concepts**\n",
        "\n",
        "Asset Management focuses on managing the **entire lifecycle** of machines and equipment so they stay reliable, safe, and cost-effective.\n",
        "\n",
        "Predictive Maintenance is a part of Asset Management, but Asset Management is **broader**\u2014it involves planning, risk assessment, health scoring, and decision-making.\n",
        "\n",
        "We explain each concept below.\n",
        "\n",
        "---\n",
        "\n",
        "# **7.1 Asset Lifecycle**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "The Asset Lifecycle describes **every stage** a machine goes through\u2014from installation to disposal.\n",
        "\n",
        "### **Stages:**\n",
        "\n",
        "1. **Design & Procurement**\n",
        "   Choosing machine type, specifications, and vendor.\n",
        "\n",
        "2. **Installation & Commissioning**\n",
        "   Machine is installed, tested, and handed over for operation.\n",
        "\n",
        "3. **Operation**\n",
        "   Machine performs daily tasks; sensor data is collected.\n",
        "\n",
        "4. **Maintenance**\n",
        "   Includes corrective, preventive, and predictive actions.\n",
        "\n",
        "5. **Degradation & Ageing**\n",
        "   Machine wears out naturally due to usage and environment.\n",
        "\n",
        "6. **Retirement/Replacement**\n",
        "   Machine is removed or replaced when performance drops too low.\n",
        "\n",
        "### **Why important:**\n",
        "\n",
        "* Helps plan long-term costs\n",
        "* Supports maintenance strategy\n",
        "* Ensures optimal machine usage\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "A motor may have a lifecycle of 10 years \u2192 maintenance decisions must extend life while reducing failure risks.\n",
        "\n",
        "---\n",
        "\n",
        "# **7.2 Failure Patterns**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Failure patterns describe **how and when** a machine typically fails.\n",
        "\n",
        "Machines do not fail randomly\u2014there are common patterns.\n",
        "\n",
        "### **Common failure patterns (from reliability engineering):**\n",
        "\n",
        "1. **Infant Mortality**\n",
        "\n",
        "   * Early sudden failures\n",
        "   * Poor installation/manufacturing defects\n",
        "\n",
        "2. **Random Failure**\n",
        "\n",
        "   * No clear pattern\n",
        "   * Caused by unexpected events\n",
        "\n",
        "3. **Wear-Out Failure**\n",
        "\n",
        "   * Slowly increasing probability of failure\n",
        "   * Caused by ageing, fatigue, corrosion\n",
        "\n",
        "### **Why important:**\n",
        "\n",
        "Understanding failure patterns helps decide:\n",
        "\n",
        "* Whether to use Preventive or Predictive Maintenance\n",
        "* What sensors to install\n",
        "* What models to train\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "Bearings show **wear-out** failure \u2192 ideal for Predictive Maintenance.\n",
        "\n",
        "---\n",
        "\n",
        "# **7.3 Risk-Based Maintenance**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Risk-Based Maintenance prioritizes machines based on **risk**, not just time or schedule.\n",
        "\n",
        "**Risk = Probability of failure \u00d7 Consequence of failure**\n",
        "\n",
        "### **Technical idea:**\n",
        "\n",
        "High-risk machines \u2192 frequent monitoring\n",
        "Low-risk machines \u2192 minimal monitoring\n",
        "\n",
        "### **Factors in risk:**\n",
        "\n",
        "* Machine criticality\n",
        "* Cost of downtime\n",
        "* Safety hazards\n",
        "* Failure impact on operations\n",
        "* Frequency of past failures\n",
        "\n",
        "### **Why useful:**\n",
        "\n",
        "Companies save money by focusing maintenance where it matters most.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "* Conveyor motor (low risk) \u2192 monthly check\n",
        "* Turbine gearbox (high risk) \u2192 continuous monitoring with sensors + PdM\n",
        "\n",
        "---\n",
        "\n",
        "# **7.4 Asset Health Index (AHI)**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "A single score (0\u2013100) that represents the **overall health** of an asset.\n",
        "\n",
        "### **How it is calculated:**\n",
        "\n",
        "* Combine sensor values\n",
        "* Normalize features\n",
        "* Use weighted scoring\n",
        "* Sometimes AI models generate the health score\n",
        "\n",
        "### **Example Components:**\n",
        "\n",
        "* Vibration intensity\n",
        "* Temperature rise\n",
        "* Load fluctuations\n",
        "* Current imbalance\n",
        "* Maintenance history\n",
        "\n",
        "### **Score Interpretation:**\n",
        "\n",
        "* **80\u2013100 \u2192 Healthy**\n",
        "* **60\u201380 \u2192 Minor wear**\n",
        "* **40\u201360 \u2192 Needs inspection**\n",
        "* **20\u201340 \u2192 High risk**\n",
        "* **0\u201320 \u2192 Critical (likely failure)**\n",
        "\n",
        "### **Why AHI is important:**\n",
        "\n",
        "* Easy to use in dashboards\n",
        "* Helps track asset performance\n",
        "* Useful for management decisions\n",
        "* Helps predict degradation trends\n",
        "\n",
        "---\n",
        "\n",
        "# **7.5 Criticality Analysis**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "A method to determine **how important** each asset is to operations.\n",
        "\n",
        "Criticality = **Importance of machine + Impact of failure**\n",
        "\n",
        "### **Factors used:**\n",
        "\n",
        "1. Safety impact\n",
        "2. Environmental impact\n",
        "3. Production loss\n",
        "4. Repair cost\n",
        "5. Availability of backup equipment\n",
        "6. Failure frequency\n",
        "\n",
        "### **Criticality Levels:**\n",
        "\n",
        "* **High criticality** \u2192 requires constant monitoring + PdM\n",
        "* **Medium** \u2192 scheduled + periodic monitoring\n",
        "* **Low** \u2192 basic preventive maintenance\n",
        "\n",
        "### **Why used:**\n",
        "\n",
        "Ensures the most important assets get priority in monitoring and maintenance investment.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "* Turbine \u2192 High criticality\n",
        "* Small exhaust fan \u2192 Low criticality\n",
        "\n",
        "---\n",
        "\n",
        "# **7.6 Dashboard Indicators**\n",
        "\n",
        "### **What it is:**\n",
        "\n",
        "Dashboards provide a **real-time visual summary** of asset performance and health.\n",
        "\n",
        "They help engineers and managers make quick decisions.\n",
        "\n",
        "### **Important dashboard indicators:**\n",
        "\n",
        "#### **1. Real-Time Sensor Values**\n",
        "\n",
        "* Temperature\n",
        "* Vibration\n",
        "* Pressure\n",
        "* Current/Voltage\n",
        "\n",
        "#### **2. Trend Graphs**\n",
        "\n",
        "* Vibration RMS over time\n",
        "* Temperature vs load\n",
        "* Degradation curve\n",
        "\n",
        "#### **3. Health Score Indicators**\n",
        "\n",
        "* Health Index radius chart\n",
        "* Green \u2192 Healthy\n",
        "* Yellow \u2192 Warning\n",
        "* Red \u2192 Critical\n",
        "\n",
        "#### **4. Fault Alerts & Alarms**\n",
        "\n",
        "* High vibration alert\n",
        "* Overheating alarm\n",
        "* Low pressure alarm\n",
        "\n",
        "#### **5. RUL Prediction Display**\n",
        "\n",
        "* Remaining hours\n",
        "* \u201cNext maintenance in X hours\u201d\n",
        "\n",
        "#### **6. Asset Performance Summary**\n",
        "\n",
        "* Downtime\n",
        "* Maintenance cost\n",
        "* Fault frequency\n",
        "* Energy consumption\n",
        "\n",
        "### **Why dashboards matter:**\n",
        "\n",
        "* Make complex data easy to understand\n",
        "* Help with fast decision-making\n",
        "* Provide transparency to management\n",
        "* Detect problems early\n",
        "\n",
        "---\n",
        "\n",
        "# **Summary Table**\n",
        "\n",
        "| Concept                | Purpose                                      |\n",
        "| ---------------------- | -------------------------------------------- |\n",
        "| Asset Lifecycle        | Manage machine from installation to disposal |\n",
        "| Failure Patterns       | Understand how machines fail                 |\n",
        "| Risk-Based Maintenance | Prioritize assets based on risk              |\n",
        "| Asset Health Index     | Single score representing health             |\n",
        "| Criticality Analysis   | Rank machines by importance                  |\n",
        "| Dashboard Indicators   | Visualize health, RUL, alerts, and trends    |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PKSrOp94KlWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **B. Hands-On Coding Content**\n",
        "\n",
        "# **1. Dataset Setup (with ipywidgets)**\n",
        "\n",
        "We will work with three commonly used Predictive Maintenance datasets:\n",
        "\n",
        "1\ufe0f\u20e3 Pump Sensor Failure Dataset (Working link)\n",
        "\n",
        "Source: openML / GitHub mirror\n",
        "\n",
        "https://raw.githubusercontent.com/numenta/NAB/master/data/realKnownCause/machine_temperature_system_failure.csv\n",
        "\n",
        "\n",
        "\u2714 Time-series sensor data\n",
        "\u2714 Contains cooling system failure pattern\n",
        "\u2714 Great for anomaly detection\n",
        "\n",
        "2\ufe0f\u20e3 Gas Turbine Sensor Data (Working link)\n",
        "\n",
        "Source: reliable GitHub mirror\n",
        "\n",
        "https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
        "\n",
        "\n",
        "\u26a0\ufe0f This is a time-series dataset we slightly repurpose for PdM.\n",
        "\u2714 Stable sensor-like numeric time series\n",
        "\u2714 Good for LSTM/RNN feature demonstration\n",
        "\n",
        "3\ufe0f\u20e3 Industrial Equipment Temperature & Load Dataset (Working link)\n",
        "\n",
        "Source: real industrial example dataset\n",
        "\n",
        "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# \u2705 **Step 1 \u2014 Install Required Libraries**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d2Ba1JBcMgmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# \ud83d\udce6 ONLINE PREDICTIVE MAINTENANCE DATASETS (100% WORKING)\n",
        "# With ipywidgets (Load + Clean + Plot)\n",
        "# ============================================================\n",
        "\n",
        "!pip install pandas numpy matplotlib ipywidgets seaborn requests\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1\ufe0f\u20e3 VERIFIED DATASET LINKS (ALL WORKING)\n",
        "# ------------------------------------------------------------\n",
        "DATASETS = {\n",
        "    \"Pump Sensor Failure (Machine Temp)\":\n",
        "        \"https://raw.githubusercontent.com/numenta/NAB/master/data/realKnownCause/machine_temperature_system_failure.csv\",\n",
        "\n",
        "    \"Gas Turbine Sensor-Like Series\":\n",
        "        \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\",\n",
        "\n",
        "    \"Industrial Equipment Temperature\":\n",
        "        \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n",
        "}\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2\ufe0f\u20e3 Widgets\n",
        "# ------------------------------------------------------------\n",
        "dataset_selector = widgets.Dropdown(\n",
        "    options=list(DATASETS.keys()),\n",
        "    value=\"Pump Sensor Failure (Machine Temp)\",\n",
        "    description=\"Select Dataset:\"\n",
        ")\n",
        "\n",
        "load_button = widgets.Button(description=\"Load Dataset\", button_style=\"success\")\n",
        "output_area = widgets.Output()\n",
        "\n",
        "display(dataset_selector, load_button, output_area)\n",
        "\n",
        "# Missing value widget\n",
        "na_strategy = widgets.Dropdown(\n",
        "    options=[\"Drop rows\", \"Fill mean\", \"Fill median\", \"Forward fill\", \"Backward fill\"],\n",
        "    value=\"Fill mean\",\n",
        "    description=\"Missing Values:\"\n",
        ")\n",
        "fix_button = widgets.Button(description=\"Apply Cleaning\", button_style=\"warning\")\n",
        "display(na_strategy, fix_button)\n",
        "\n",
        "# Sensor plot\n",
        "column_selector = widgets.Dropdown(description=\"Select Column:\")\n",
        "plot_button = widgets.Button(description=\"Plot Column\", button_style=\"info\")\n",
        "display(column_selector, plot_button)\n",
        "\n",
        "current_df = None\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3\ufe0f\u20e3 Missing value function\n",
        "# ------------------------------------------------------------\n",
        "def clean_missing(df, method):\n",
        "    if method == \"Drop rows\":\n",
        "        return df.dropna()\n",
        "    if method == \"Fill mean\":\n",
        "        return df.fillna(df.mean(numeric_only=True))\n",
        "    if method == \"Fill median\":\n",
        "        return df.fillna(df.median(numeric_only=True))\n",
        "    if method == \"Forward fill\":\n",
        "        return df.fillna(method=\"ffill\")\n",
        "    if method == \"Backward fill\":\n",
        "        return df.fillna(method=\"bfill\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4\ufe0f\u20e3 Load dataset callback\n",
        "# ------------------------------------------------------------\n",
        "def on_load_clicked(b):\n",
        "    global current_df\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        name = dataset_selector.value\n",
        "        url = DATASETS[name]\n",
        "\n",
        "        display(Markdown(f\"## \ud83d\udce5 Loading Dataset: **{name}**\"))\n",
        "        display(Markdown(f\"**Source URL:** {url}\"))\n",
        "\n",
        "        df = pd.read_csv(url)\n",
        "        current_df = df\n",
        "\n",
        "        display(Markdown(\"### \u2705 Dataset Loaded\"))\n",
        "        display(df.head())\n",
        "\n",
        "        # populate column selector\n",
        "        column_selector.options = df.columns.tolist()\n",
        "\n",
        "load_button.on_click(on_load_clicked)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5\ufe0f\u20e3 Apply Cleaning\n",
        "# ------------------------------------------------------------\n",
        "def on_clean_clicked(b):\n",
        "    global current_df\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        if current_df is None:\n",
        "            display(Markdown(\"### \u2757 Load dataset first.\"))\n",
        "            return\n",
        "\n",
        "        current_df = clean_missing(current_df, na_strategy.value)\n",
        "\n",
        "        display(Markdown(f\"## \ud83e\uddf9 Cleaning Applied \u2014 **{na_strategy.value}**\"))\n",
        "        display(current_df.head())\n",
        "\n",
        "fix_button.on_click(on_clean_clicked)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6\ufe0f\u20e3 Plotting Callback\n",
        "# ------------------------------------------------------------\n",
        "def on_plot_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        if current_df is None:\n",
        "            display(Markdown(\"### \u2757 Load dataset first.\"))\n",
        "            return\n",
        "\n",
        "        col = column_selector.value\n",
        "        display(Markdown(f\"## \ud83d\udcc8 Plot for Column \u2014 **{col}**\"))\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.plot(current_df[col])\n",
        "        plt.grid(True)\n",
        "        plt.title(f\"{col} Trend\")\n",
        "        plt.xlabel(\"Index\")\n",
        "        plt.ylabel(col)\n",
        "        plt.show()\n",
        "\n",
        "plot_button.on_click(on_plot_clicked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75f81684af804c2db59fca3ced04aa7b",
            "ab86343fcb27486f9ec876035975c4c2",
            "d044284cb6fd4861ac5346fdf95f4680",
            "eabbb27fded8491197923a135cbc937f",
            "8f94187b71f144b191ef41483c8e247f",
            "47df53d48c3142cd8b3b7c807850cb5a",
            "149096bd233e4c5caa9a326740aa4e75",
            "53206678bb91432abcac57e2f750b0a5",
            "ce207d50f625404cb9e1c3afed93c29b",
            "88df939645fe408db2353ab6b8910d72",
            "5c9f778698264e9eaf01e0af3e3bc6ae",
            "0bd1de2480ac4f178c2e4190d2ea1546",
            "d7cf75660ef04e15852fa5b5eb13a576",
            "27d2527933d64821af3bc3480573afe8",
            "54a1f5078659457bb45bc3a4f9a82b51",
            "88ba48aa7c094a4a9c6aaa23c109daf3",
            "9f440940c66c46d6abef6f35c318f6e2",
            "3dc13b5229b94c5ab239ec28c10c3056",
            "5673de22c3444f68b8ee9f6c40d4c299",
            "0eb9308f023343939de73867262579bb"
          ]
        },
        "id": "uNQVqtYIRWnH",
        "outputId": "e7373a4f-9399-439c-ac53-1c4d8c3e5f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.28.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Select Dataset:', options=('Pump Sensor Failure (Machine Temp)', 'Gas Turbine Sensor-Lik\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75f81684af804c2db59fca3ced04aa7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Load Dataset', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eabbb27fded8491197923a135cbc937f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "149096bd233e4c5caa9a326740aa4e75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Missing Values:', index=1, options=('Drop rows', 'Fill mean', 'Fill median', 'Forward fi\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce207d50f625404cb9e1c3afed93c29b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='warning', description='Apply Cleaning', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bd1de2480ac4f178c2e4190d2ea1546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Select Column:', options=(), value=None)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a1f5078659457bb45bc3a4f9a82b51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='info', description='Plot Column', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dc13b5229b94c5ab239ec28c10c3056"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2\ufe0f\u20e3 FEATURE ENGINEERING IN CODE\n",
        "# Scaling \u2022 Rolling Stats \u2022 Lag Features \u2022 FFT \u2022 Windows \u2022 RUL\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(\"## \u2699\ufe0f Step 2 \u2014 Feature Engineering\"))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Widgets\n",
        "# ------------------------------------------------------------\n",
        "window_size_slider = widgets.IntSlider(\n",
        "    value=30, min=5, max=200, step=5,\n",
        "    description=\"Window Size:\", style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "lag_slider = widgets.IntSlider(\n",
        "    value=3, min=1, max=10, step=1,\n",
        "    description=\"Lag Count:\", style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "fft_slider = widgets.IntSlider(\n",
        "    value=5, min=1, max=20, step=1,\n",
        "    description=\"FFT Components:\", style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "generate_features_button = widgets.Button(\n",
        "    description=\"Generate Feature Matrix\",\n",
        "    button_style=\"primary\"\n",
        ")\n",
        "\n",
        "feature_output = widgets.Output()\n",
        "\n",
        "display(window_size_slider, lag_slider, fft_slider, generate_features_button, feature_output)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helper Function: Create Feature Matrix\n",
        "# ------------------------------------------------------------\n",
        "def create_feature_matrix(series, window_size=30, n_lags=3, n_fft=5):\n",
        "    \"\"\"\n",
        "    Takes a numeric time-series and generates a PdM feature matrix containing:\n",
        "    - Scaling\n",
        "    - Rolling statistics\n",
        "    - Lag features\n",
        "    - FFT frequency features\n",
        "    - RUL labels\n",
        "    \"\"\"\n",
        "    values = pd.to_numeric(series, errors='coerce').dropna().values\n",
        "    N = len(values)\n",
        "\n",
        "    # Min\u2013Max Scaling\n",
        "    vmin, vmax = values.min(), values.max()\n",
        "    scaled = (values - vmin) / (vmax - vmin + 1e-9)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for start in range(0, N - window_size):\n",
        "        end = start + window_size\n",
        "        window_vals = scaled[start:end]\n",
        "\n",
        "        row = {\n",
        "            \"window_start\": start,\n",
        "            \"window_end\": end - 1\n",
        "        }\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # Rolling Statistical Features\n",
        "        # ----------------------------------------------------\n",
        "        row[\"mean\"] = window_vals.mean()\n",
        "        row[\"std\"] = window_vals.std()\n",
        "        row[\"min\"] = window_vals.min()\n",
        "        row[\"max\"] = window_vals.max()\n",
        "        row[\"rms\"] = np.sqrt(np.mean(window_vals ** 2))\n",
        "        row[\"last_value\"] = window_vals[-1]\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # Lag Features\n",
        "        # ----------------------------------------------------\n",
        "        for k in range(1, n_lags + 1):\n",
        "            idx = end - k\n",
        "            row[f\"lag_{k}\"] = scaled[idx] if idx >= 0 else np.nan\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # FFT Frequency Features\n",
        "        # ----------------------------------------------------\n",
        "        fft_vals = np.abs(np.fft.rfft(window_vals))\n",
        "        for j in range(1, n_fft + 1):\n",
        "            row[f\"fft_{j}\"] = fft_vals[j] if j < len(fft_vals) else np.nan\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # Remaining Useful Life Labels\n",
        "        # ----------------------------------------------------\n",
        "        row[\"RUL\"] = N - end\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# CALLBACK: Generate Features\n",
        "# ------------------------------------------------------------\n",
        "def on_generate_features_clicked(b):\n",
        "    with feature_output:\n",
        "        feature_output.clear_output()\n",
        "\n",
        "        if current_df is None:\n",
        "            display(Markdown(\"### \u2757 Load and clean a dataset first.\"))\n",
        "            return\n",
        "\n",
        "        col = column_selector.value\n",
        "        if col is None:\n",
        "            display(Markdown(\"### \u2757 Select a column first.\"))\n",
        "            return\n",
        "\n",
        "        # Ensure selected column is numeric\n",
        "        if not pd.api.types.is_numeric_dtype(current_df[col]):\n",
        "            display(Markdown(f\"### \u2757 Column **{col}** is not numeric.\"))\n",
        "            display(Markdown(\"Select a numeric sensor/value column.\"))\n",
        "            return\n",
        "\n",
        "        series = current_df[col].dropna().reset_index(drop=True)\n",
        "\n",
        "        display(Markdown(f\"## \ud83e\uddee Feature Engineering for Column: **{col}**\"))\n",
        "        display(Markdown(\n",
        "            f\"- Window Size: **{window_size_slider.value}**  \\n\"\n",
        "            f\"- Lag Count: **{lag_slider.value}**  \\n\"\n",
        "            f\"- FFT Components: **{fft_slider.value}**\"\n",
        "        ))\n",
        "\n",
        "        # ------------------------------------\n",
        "        # \u2b50 FIX: Store feature matrix globally\n",
        "        # ------------------------------------\n",
        "        global features_df_global\n",
        "        features_df_global = create_feature_matrix(\n",
        "            series,\n",
        "            window_size=window_size_slider.value,\n",
        "            n_lags=lag_slider.value,\n",
        "            n_fft=fft_slider.value\n",
        "        )\n",
        "\n",
        "        display(Markdown(\"### \ud83d\udcd8 First 10 Rows of Feature Matrix\"))\n",
        "        display(features_df_global.head(10))\n",
        "\n",
        "        display(Markdown(\"### \ud83d\udd22 Feature Matrix Shape\"))\n",
        "        display(Markdown(f\"- Rows: **{features_df_global.shape[0]}**\"))\n",
        "        display(Markdown(f\"- Columns: **{features_df_global.shape[1]}**\"))\n",
        "\n",
        "generate_features_button.on_click(on_generate_features_clicked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765,
          "referenced_widgets": [
            "4a03ef6c819b4d1883846b909ab53080",
            "80ddfc811bdf4bd4bdf44f994de74f09",
            "2611bf5dd77447fea031e28e4a6cd4f6",
            "a957616927db4685a3044113f39cd7fc",
            "865c973153064e6ca0a9daec49066c08",
            "9a4e2d57a9ce481c886b16d6019a2425",
            "49b86941eeaa401696b9bfb4b53f5749",
            "3d67c72d6ac743df90cb5b9f6546f227",
            "44a007c09e8e4e3c96b0a4299ee8becf",
            "86cf1ae30c134854b9768057cac3786f",
            "ac66ae1b923b439bba7611f8e101a179",
            "e525e077f68b471488dabb42076f78e9",
            "4f73f24efcbf4b089eae6e41e675c7e5",
            "921666c84e9a4d41bac4bfab990a225d"
          ]
        },
        "id": "YMHHuOR6ZDxb",
        "outputId": "bf8de4da-cd17-4257-b914-c8b69e87c6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## \u2699\ufe0f Step 2 \u2014 Feature Engineering"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=30, description='Window Size:', max=200, min=5, step=5, style=SliderStyle(description_width='i\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a03ef6c819b4d1883846b909ab53080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=3, description='Lag Count:', max=10, min=1, style=SliderStyle(description_width='initial'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a957616927db4685a3044113f39cd7fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=5, description='FFT Components:', max=20, min=1, style=SliderStyle(description_width='initial'\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49b86941eeaa401696b9bfb4b53f5749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Generate Feature Matrix', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86cf1ae30c134854b9768057cac3786f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f73f24efcbf4b089eae6e41e675c7e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3\ufe0f\u20e3 ML MODEL TRAINING \u2014 WITH LIVE TRAINING OUTPUT\n",
        "# ============================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error, mean_squared_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# Global storage for ML training\n",
        "generated_features_df = None\n",
        "\n",
        "# ============================================================\n",
        "# ONE SINGLE OUTPUT AREA FOR EVERYTHING\n",
        "# ============================================================\n",
        "train_output = widgets.Output()\n",
        "display(Markdown(\"## \ud83e\uddfe Step 3 \u2014 ML Model Training\"))\n",
        "display(train_output)\n",
        "\n",
        "# ============================================================\n",
        "# SAVE FEATURE MATRIX BUTTON\n",
        "# ============================================================\n",
        "save_features_button = widgets.Button(\n",
        "    description=\"Save Feature Matrix\",\n",
        "    button_style=\"success\"\n",
        ")\n",
        "display(save_features_button)\n",
        "\n",
        "def on_save_features_clicked(b):\n",
        "    global generated_features_df\n",
        "    with train_output:\n",
        "        train_output.clear_output()\n",
        "\n",
        "        if \"features_df_global\" not in globals():\n",
        "            display(Markdown(\"### \u2757 Please generate features first in Step 2.\"))\n",
        "            return\n",
        "\n",
        "        generated_features_df = features_df_global.copy()\n",
        "        display(Markdown(\"### \u2705 Feature Matrix Saved Successfully\"))\n",
        "        display(generated_features_df.head())\n",
        "\n",
        "save_features_button.on_click(on_save_features_clicked)\n",
        "\n",
        "# ============================================================\n",
        "# MODEL SELECTION + TRAIN BUTTON\n",
        "# ============================================================\n",
        "model_type_selector = widgets.Dropdown(\n",
        "    options=[\"RUL Regression\", \"Binary Classification (High vs Low RUL)\"],\n",
        "    value=\"RUL Regression\",\n",
        "    description=\"Model Type:\"\n",
        ")\n",
        "\n",
        "train_button = widgets.Button(\n",
        "    description=\"Train Model\",\n",
        "    button_style=\"primary\"\n",
        ")\n",
        "\n",
        "display(model_type_selector, train_button)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def train_regression_model(df):\n",
        "    X = df.drop(columns=[\"RUL\"])\n",
        "    y = df[\"RUL\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, shuffle=False\n",
        "    )\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    return model, preds, y_test\n",
        "\n",
        "\n",
        "def train_classification_model(df):\n",
        "    df = df.copy()\n",
        "    threshold = df[\"RUL\"].median()\n",
        "    df[\"label\"] = (df[\"RUL\"] < threshold).astype(int)\n",
        "\n",
        "    X = df.drop(columns=[\"RUL\", \"label\"])\n",
        "    y = df[\"label\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, shuffle=False\n",
        "    )\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    return model, preds, y_test\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN BUTTON CALLBACK (WITH LIVE STATUS MESSAGES)\n",
        "# ============================================================\n",
        "def on_train_clicked(b):\n",
        "    with train_output:\n",
        "        train_output.clear_output()\n",
        "\n",
        "        if generated_features_df is None:\n",
        "            display(Markdown(\"### \u2757 Please click **Save Feature Matrix** first.\"))\n",
        "            return\n",
        "\n",
        "        df = generated_features_df.copy()\n",
        "        model_type = model_type_selector.value\n",
        "\n",
        "        # ------------------------------------------\n",
        "        # LIVE MESSAGE FEEDBACK\n",
        "        # ------------------------------------------\n",
        "        print(\"\u23f3 Starting Training...\")\n",
        "        display(Markdown(\"### \u23f3 Training started\u2026 Please wait.\"))\n",
        "\n",
        "        time.sleep(0.5)\n",
        "        print(\"\ud83d\udccc Splitting dataset...\")\n",
        "        time.sleep(0.4)\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # RUL REGRESSION\n",
        "        # ----------------------------------------------------\n",
        "        if model_type == \"RUL Regression\":\n",
        "            display(Markdown(\"## \ud83d\udd27 Training RUL Regression Model...\"))\n",
        "\n",
        "            model, preds, y_test = train_regression_model(df)\n",
        "\n",
        "            print(\"\ud83d\udccc Calculating metrics...\")\n",
        "            time.sleep(0.3)\n",
        "\n",
        "            mae = mean_absolute_error(y_test, preds)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "            r2 = r2_score(y_test, preds)\n",
        "\n",
        "            display(Markdown(\"### \ud83d\udcca Regression Metrics\"))\n",
        "            display(Markdown(f\"- **MAE:** {mae:.4f}\"))\n",
        "            display(Markdown(f\"- **RMSE:** {rmse:.4f}\"))\n",
        "            display(Markdown(f\"- **R\u00b2 Score:** {r2:.4f}\"))\n",
        "\n",
        "            print(\"\ud83d\udcc8 Plotting results...\")\n",
        "            time.sleep(0.3)\n",
        "\n",
        "            plt.figure(figsize=(12,4))\n",
        "            plt.plot(y_test.values, label=\"Actual RUL\", linewidth=2)\n",
        "            plt.plot(preds, label=\"Predicted RUL\", linestyle=\"dashed\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.title(\"Actual vs Predicted RUL\")\n",
        "            plt.show()\n",
        "\n",
        "            display(Markdown(\"### \u2705 Training Completed Successfully\"))\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # BINARY CLASSIFICATION\n",
        "        # ----------------------------------------------------\n",
        "        else:\n",
        "            display(Markdown(\"## \ud83d\udd27 Training High/Low Risk Classifier...\"))\n",
        "\n",
        "            model, preds, y_test = train_classification_model(df)\n",
        "\n",
        "            print(\"\ud83d\udccc Evaluating predictions...\")\n",
        "            time.sleep(0.3)\n",
        "\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            prec = precision_score(y_test, preds)\n",
        "            rec = recall_score(y_test, preds)\n",
        "            f1 = f1_score(y_test, preds)\n",
        "\n",
        "            display(Markdown(\"### \ud83d\udcca Classification Metrics\"))\n",
        "            display(Markdown(f\"- **Accuracy:** {acc:.4f}\"))\n",
        "            display(Markdown(f\"- **Precision:** {prec:.4f}\"))\n",
        "            display(Markdown(f\"- **Recall:** {rec:.4f}\"))\n",
        "            display(Markdown(f\"- **F1 Score:** {f1:.4f}\"))\n",
        "\n",
        "            print(\"\ud83d\udcc8 Plotting results...\")\n",
        "            time.sleep(0.3)\n",
        "\n",
        "            plt.figure(figsize=(12,4))\n",
        "            plt.plot(y_test.values, label=\"True Class\", linewidth=2)\n",
        "            plt.plot(preds, label=\"Predicted Class\", linestyle='dashed')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.title(\"High/Low Risk Classification\")\n",
        "            plt.show()\n",
        "\n",
        "            display(Markdown(\"### \u2705 Training Completed Successfully\"))\n",
        "\n",
        "train_button.on_click(on_train_clicked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845,
          "referenced_widgets": [
            "3276867c389c41e7826cd10fd702f959",
            "6e7c1229df584be0a99ea9143d6479e3",
            "ffed459097a74a65863f9fe4eea99a77",
            "6952fcc842fb448ba5e04a2358054a27",
            "24f952b405f84efcbd256e76a781cf5b",
            "b9525da4257745c3b362860075277d00",
            "ae5968cd543049b4a4b09ffbe94b543b",
            "205b205993e2451995973a0af049d48c",
            "6c00950713714f2ab5f9b87cedd79a0f",
            "1b6468e9fbb0492d81bdbf47222f24ca",
            "2c93b8c239d74ac1b3944156ac37000f"
          ]
        },
        "id": "7505VQMImGtg",
        "outputId": "9ca97076-e96e-469b-e14f-ec2cd3668d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## \ud83e\uddfe Step 3 \u2014 ML Model Training"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3276867c389c41e7826cd10fd702f959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Save Feature Matrix', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffed459097a74a65863f9fe4eea99a77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Model Type:', options=('RUL Regression', 'Binary Classification (High vs Low RUL)'), val\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9525da4257745c3b362860075277d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Train Model', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c00950713714f2ab5f9b87cedd79a0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4\ufe0f\u20e3 DEEP LEARNING MODELS FOR PREDICTIVE MAINTENANCE\n",
        "# LSTM Forecasting + Autoencoder Anomaly Detection\n",
        "# ============================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(\"## \ud83e\udd16 Step 4 \u2014 Deep Learning Models\"))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Widgets for DL configuration\n",
        "# ------------------------------------------------------------\n",
        "dl_model_selector = widgets.Dropdown(\n",
        "    options=[\"LSTM Forecasting\", \"Autoencoder Anomaly Detection\"],\n",
        "    value=\"LSTM Forecasting\",\n",
        "    description=\"DL Model:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "seq_len_slider = widgets.IntSlider(\n",
        "    value=30, min=5, max=100, step=5,\n",
        "    description=\"Sequence Length:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "epochs_slider = widgets.IntSlider(\n",
        "    value=5, min=1, max=30, step=1,\n",
        "    description=\"Epochs:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "batch_slider = widgets.IntSlider(\n",
        "    value=32, min=8, max=128, step=8,\n",
        "    description=\"Batch Size:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "dl_train_button = widgets.Button(\n",
        "    description=\"Train DL Model\",\n",
        "    button_style=\"primary\"\n",
        ")\n",
        "\n",
        "dl_output = widgets.Output()\n",
        "\n",
        "display(dl_model_selector, seq_len_slider, epochs_slider, batch_slider, dl_train_button, dl_output)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helper: Build sequences from a 1D time series\n",
        "# ------------------------------------------------------------\n",
        "def build_sequences(values, seq_len=30):\n",
        "    \"\"\"\n",
        "    Given a 1D numpy array, create overlapping sequences:\n",
        "    X: sequences of length seq_len\n",
        "    y: next value (for forecasting)\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(values) - seq_len):\n",
        "        X.append(values[i:i+seq_len])\n",
        "        y.append(values[i+seq_len])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X for LSTM: (samples, timesteps, features)\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "    return X, y\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# LSTM Model Builder\n",
        "# ------------------------------------------------------------\n",
        "def build_lstm_model(seq_len):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(seq_len, 1)),\n",
        "        layers.LSTM(32, return_sequences=False),\n",
        "        layers.Dense(16, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Autoencoder Model Builder (Dense on Flattened Window)\n",
        "# ------------------------------------------------------------\n",
        "def build_autoencoder(seq_len):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(seq_len,)),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(seq_len)  # reconstruct original window\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# CALLBACK: Train DL Model\n",
        "# ------------------------------------------------------------\n",
        "def on_dl_train_clicked(b):\n",
        "    with dl_output:\n",
        "        dl_output.clear_output()\n",
        "\n",
        "        if current_df is None:\n",
        "            display(Markdown(\"### \u2757 Please load and clean a dataset first (Step 1).\"))\n",
        "            return\n",
        "\n",
        "        col = column_selector.value\n",
        "        if col is None:\n",
        "            display(Markdown(\"### \u2757 Please select a column (sensor) in Step 1.\"))\n",
        "            return\n",
        "\n",
        "        # Ensure numeric\n",
        "        if not pd.api.types.is_numeric_dtype(current_df[col]):\n",
        "            display(Markdown(f\"### \u2757 Column **{col}** is not numeric. Select a numeric sensor column.\"))\n",
        "            return\n",
        "\n",
        "        seq_len = seq_len_slider.value\n",
        "        epochs = epochs_slider.value\n",
        "        batch_size = batch_slider.value\n",
        "        model_type = dl_model_selector.value\n",
        "\n",
        "        # Prepare series\n",
        "        series = current_df[col].dropna().reset_index(drop=True).values.astype(float)\n",
        "\n",
        "        if len(series) <= seq_len + 5:\n",
        "            display(Markdown(\"### \u2757 Time series too short for the selected sequence length.\"))\n",
        "            return\n",
        "\n",
        "        # Min\u2013Max scaling\n",
        "        vmin, vmax = series.min(), series.max()\n",
        "        scaled = (series - vmin) / (vmax - vmin + 1e-9)\n",
        "\n",
        "        display(Markdown(f\"## \ud83e\udd16 Training **{model_type}** on Column: **{col}**\"))\n",
        "        display(Markdown(\n",
        "            f\"- Sequence Length: **{seq_len}**  \\n\"\n",
        "            f\"- Epochs: **{epochs}**  \\n\"\n",
        "            f\"- Batch Size: **{batch_size}**\"\n",
        "        ))\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # LSTM FORECASTING\n",
        "        # ----------------------------------------------------\n",
        "        if model_type == \"LSTM Forecasting\":\n",
        "            print(\"\u23f3 Building sequences for forecasting...\")\n",
        "            X, y = build_sequences(scaled, seq_len=seq_len)\n",
        "\n",
        "            # Train/test split\n",
        "            split_idx = int(len(X) * 0.8)\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "            print(\"\ud83d\udccc Building LSTM model...\")\n",
        "            model = build_lstm_model(seq_len)\n",
        "\n",
        "            print(\"\ud83d\ude80 Training LSTM...\")\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            print(\"\ud83d\udccc Predicting on test set...\")\n",
        "            y_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "            # Rescale back to original units\n",
        "            y_test_real = y_test * (vmax - vmin + 1e-9) + vmin\n",
        "            y_pred_real = y_pred.flatten() * (vmax - vmin + 1e-9) + vmin\n",
        "\n",
        "            # Metrics\n",
        "            mae = mean_absolute_error(y_test_real, y_pred_real)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
        "\n",
        "            display(Markdown(\"### \ud83d\udcca LSTM Forecasting Metrics\"))\n",
        "            display(Markdown(f\"- **MAE:** {mae:.4f}\"))\n",
        "            display(Markdown(f\"- **RMSE:** {rmse:.4f}\"))\n",
        "\n",
        "            # Plot forecast vs actual\n",
        "            plt.figure(figsize=(12,4))\n",
        "            plt.plot(y_test_real, label=\"Actual\", linewidth=2)\n",
        "            plt.plot(y_pred_real, label=\"Predicted\", linestyle=\"dashed\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.title(f\"LSTM Forecasting \u2014 {col}\")\n",
        "            plt.show()\n",
        "\n",
        "            # Optional: Training loss curve\n",
        "            plt.figure(figsize=(8,4))\n",
        "            plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "            plt.plot(history.history.get(\"val_loss\", []), label=\"Validation Loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"LSTM Training Loss Curve\")\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "            display(Markdown(\"### \u2705 LSTM Training Completed\"))\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # AUTOENCODER ANOMALY DETECTION\n",
        "        # ----------------------------------------------------\n",
        "        else:\n",
        "            print(\"\u23f3 Creating windowed data for Autoencoder...\")\n",
        "            # Create overlapping windows as flat vectors\n",
        "            windows = []\n",
        "            for i in range(len(scaled) - seq_len):\n",
        "                windows.append(scaled[i:i+seq_len])\n",
        "            windows = np.array(windows)\n",
        "\n",
        "            # Train/test split\n",
        "            split_idx = int(len(windows) * 0.8)\n",
        "            X_train = windows[:split_idx]\n",
        "            X_test = windows[split_idx:]\n",
        "\n",
        "            print(\"\ud83d\udccc Building Autoencoder model...\")\n",
        "            autoencoder = build_autoencoder(seq_len)\n",
        "\n",
        "            print(\"\ud83d\ude80 Training Autoencoder...\")\n",
        "            history = autoencoder.fit(\n",
        "                X_train, X_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=0.2,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            print(\"\ud83d\udccc Computing reconstruction errors...\")\n",
        "            # Reconstruction on train + test\n",
        "            train_recon = autoencoder.predict(X_train, verbose=0)\n",
        "            test_recon = autoencoder.predict(X_test, verbose=0)\n",
        "\n",
        "            train_errors = np.mean((X_train - train_recon)**2, axis=1)\n",
        "            test_errors = np.mean((X_test - test_recon)**2, axis=1)\n",
        "\n",
        "            # Threshold: mean + 2*std of training errors\n",
        "            threshold = train_errors.mean() + 2 * train_errors.std()\n",
        "\n",
        "            # Flag anomalies in test\n",
        "            anomalies = test_errors > threshold\n",
        "            num_anomalies = anomalies.sum()\n",
        "\n",
        "            display(Markdown(\"### \ud83d\udcca Autoencoder Anomaly Detection Summary\"))\n",
        "            display(Markdown(f\"- **Threshold:** {threshold:.6f} (mean + 2\u00b7std of train error)\"))\n",
        "            display(Markdown(f\"- **Total Test Windows:** {len(test_errors)}\"))\n",
        "            display(Markdown(f\"- **Anomalous Windows Detected:** **{num_anomalies}**\"))\n",
        "\n",
        "            # Plot reconstruction error\n",
        "            plt.figure(figsize=(12,4))\n",
        "            plt.plot(test_errors, label=\"Reconstruction Error\")\n",
        "            plt.axhline(threshold, color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
        "            plt.title(f\"Autoencoder Reconstruction Error \u2014 {col}\")\n",
        "            plt.xlabel(\"Test Window Index\")\n",
        "            plt.ylabel(\"MSE\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "            # Optional: Training loss curve\n",
        "            plt.figure(figsize=(8,4))\n",
        "            plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "            plt.plot(history.history.get(\"val_loss\", []), label=\"Validation Loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Autoencoder Training Loss Curve\")\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "            display(Markdown(\"### \u2705 Autoencoder Training Completed\"))\n",
        "\n",
        "dl_train_button.on_click(on_dl_train_clicked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "ef555a0eee2d491c86fcbb94af230a61",
            "3c5db8c0160f46bba186dd3f03137d9e",
            "c0f203ebc2184e98a34269a1fa978e79",
            "5af97b03bab44d76a6c65cc138062abf",
            "45c2cd465b5940138eb9db850c679c2a",
            "356108c4629a4df8a0861a1567ea14b6",
            "6997b8cd80d343eaa56a9a029bcdedaa",
            "de056fe08e0442b1bfaa1b446eb64559",
            "8b44326afd4246b19814dbee2587e987",
            "21a5755a7c684ac7a951dbeaa25446de",
            "f9bcb4986ba84783b9433fe685d9b7cf",
            "59f430a0883746968d3266679788b299",
            "836dc2d6ecd24333bbd604c3249b8300",
            "368d6005e567448694c7c64323ccdcc4",
            "c818ef09d77641c7aaba2e3405020df0",
            "0d453db38a9344baa4f62204146f6b6b",
            "b57f126b8fb142cda669615e4d3e7979"
          ]
        },
        "id": "h868QNbrunEs",
        "outputId": "fa1bcdb1-6cd1-47d3-e92f-9bd3eb167bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## \ud83e\udd16 Step 4 \u2014 Deep Learning Models"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='DL Model:', options=('LSTM Forecasting', 'Autoencoder Anomaly Detection'), style=Descrip\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef555a0eee2d491c86fcbb94af230a61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=30, description='Sequence Length:', min=5, step=5, style=SliderStyle(description_width='initia\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5af97b03bab44d76a6c65cc138062abf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=5, description='Epochs:', max=30, min=1, style=SliderStyle(description_width='initial'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6997b8cd80d343eaa56a9a029bcdedaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=32, description='Batch Size:', max=128, min=8, step=8, style=SliderStyle(description_width='in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21a5755a7c684ac7a951dbeaa25446de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Train DL Model', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "836dc2d6ecd24333bbd604c3249b8300"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d453db38a9344baa4f62204146f6b6b"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}